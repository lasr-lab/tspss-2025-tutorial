{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 1: Extract and Load Pre-collected Data\n",
    "\n",
    "Since we don't have access to the OpenTouch Interface on Mac, we'll use\n",
    "pre-collected touch sensor data that has already been captured.\n",
    "\n",
    "* The coin_data.zip file contains organized PNG images from different coin types.\n",
    "* Each folder represents a different class/label (e.g., one_euro, two_euro, etc.).\n",
    "* We'll extract this data and inspect its structure.\n",
    "\n",
    "Note: This data was originally collected using DIGIT touch sensors on Ubuntu.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "zip_path = \"coin_data.zip\"\n",
    "extract_dir = Path(os.path.splitext(zip_path)[0] + \"_extracted\")\n",
    "\n",
    "# TODO: Extract the dataset into the extraction directory and inspect its contents\n"
   ],
   "id": "412ff0ea1063c61a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 2: Load Images for One Label\n",
    "\n",
    "Load the images from one coin type folder into a camera_data list.\n",
    "This simulates what would happen when loading data from a single .touch file.\n",
    "\n",
    "* Choose which coin type folder to process (e.g., \"two_euro\", \"one_euro\").\n",
    "* Load all images from that folder into a list of numpy arrays.\n",
    "* This creates the same `camera_data` variable as in the sensor data workflow.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# TODO: Load all images from one chosen coin type folder into camera_data\n",
    "label_name = \"two_euro\"\n",
    "\n",
    "...\n",
    "\n",
    "camera_data: list = [...]\n"
   ],
   "id": "9c7d50c169c8fdf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 3: Filter the Frames\n",
    "\n",
    "Each dataset should only contain images of its respective label.\n",
    "Remove frames that don't match (e.g., \"no touch\" images in a \"coin\" dataset).\n",
    "\n",
    "Why?\n",
    "The raw data also includes unwanted frames (like empty touches or noise).\n",
    "Filtering ensures that each dataset is clean and only contains the intended label.\n",
    "\n",
    "* Exception: If you are creating a \"no touch\" dataset, keep the empty frames.\n",
    "* Hint: You can do this both programmatically and using your file explorer.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Implement a filtering strategy to remove \"no touch\" or irrelevant frames\n",
    "#       (e.g., by comparing with an average empty frame or by manual inspection)\n",
    "\n",
    "with_touch: list = [...]\n"
   ],
   "id": "435d900fdb0ece58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 4: Save the Cleaned Dataset\n",
    "\n",
    "Now save the filtered frames to disk.\n",
    "\n",
    "* Saving them as `.png` files makes it easy to inspect the images in your file explorer.\n",
    "* Each dataset (per label) will be stored in its own folder.\n",
    "\n",
    "DON'T MODIFY THIS CELL. SIMPLY RUN.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Use the label name as the dataset name\n",
    "directory = os.path.join('coin_data', label_name)\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f'Saving {len(with_touch)} images to {directory}/')\n",
    "for i, frame in enumerate(with_touch):\n",
    "    img = Image.fromarray(frame.astype(np.uint8))\n",
    "    img.save(os.path.join(directory, f'{label_name}_{i:04d}.png'))"
   ],
   "id": "bbe2a788bf86ce6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 5: Create a simple model to convert RGB images to grayscale.\n",
    "\n",
    "* The filter converts RGB images to grayscale using the standard luminosity method.\n",
    "* Then display the original and grayscale images side by side.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Implement a function to convert an RGB image to grayscale\n",
    "\n",
    "# TODO: Pick one image from the dataset and apply your grayscale function\n",
    "\n",
    "# TODO: Display the original and grayscale images side by side\n"
   ],
   "id": "f6748f509696ceb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 6: Define the CNN Model\n",
    "\n",
    "We now build a Convolutional Neural Network (CNN) to classify the coins.\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class CoinClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # TODO: Define the CNN architecture here\n",
    "        self.model = ...\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass through the CNN\"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Preprocess input images from [N, H, W, C] to [N, C, H, W].\n",
    "        Normalizes pixel values from [0, 255] to [0, 1].\n",
    "        \"\"\"\n",
    "        x = x.float() / 255.0\n",
    "        return x.permute(0, 3, 1, 2)\n"
   ],
   "id": "c3594f49acd66f70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "This is an alternative to Step 6 where we use a pre-trained model from PyTorch.\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class CoinClassifierEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "\n",
    "        # TODO: Load a pretrained EfficientNet-B4 backbone\n",
    "        # TODO: Freeze its parameters\n",
    "        # TODO: Replace the classifier head to match num_classes\n",
    "\n",
    "        self.model = ...\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Preprocess input images from [N, H, W, C] uint8 [0, 255].\n",
    "        Converts to [N, C, 380, 380] float32 normalized for EfficientNet.\n",
    "        \"\"\"\n",
    "        x = x.float() / 255.0\n",
    "        x = x.permute(0, 3, 1, 2)  # [N, C, H, W]\n",
    "\n",
    "        inout_h, input_w = 240, 320\n",
    "        target_size = 380\n",
    "\n",
    "        # Scale while preserving aspect ratio\n",
    "        scale = min(target_size / inout_h, target_size / input_w)\n",
    "        new_h, new_w = int(inout_h * scale), int(input_w * scale)\n",
    "\n",
    "        x = torch.nn.functional.interpolate(\n",
    "            x, size=(new_h, new_w), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "\n",
    "        # Pad to square\n",
    "        pad_h = target_size - new_h\n",
    "        pad_w = target_size - new_w\n",
    "        pad_top = pad_h // 2\n",
    "        pad_left = pad_w // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        pad_right = pad_w - pad_left\n",
    "\n",
    "        x = torch.nn.functional.pad(x, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "\n",
    "        # ImageNet normalization\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(x.device)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(x.device)\n",
    "        x = (x - mean) / std\n",
    "\n",
    "        return x\n"
   ],
   "id": "7c2b64a51bd8b1fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 7: Load the Coin Datasets\n",
    "\n",
    "Now we load the saved images back into memory.\n",
    "\n",
    "* Each coin type should be in its own subdirectory under `coin_data/`.\n",
    "* A label mapping is created automatically from the folder names.\n",
    "* Optionally, datasets are balanced so all classes have the same number of images.\n",
    "\n",
    "DON'T MODIFY THIS CELL. SIMPLY RUN.\n",
    "\"\"\"\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_coin_datasets(dset_path: str, balance_datasets = True, max_size=2000) -> tuple[np.ndarray, np.ndarray, dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Load coin images from subdirectories\n",
    "\n",
    "    Expected structure:\n",
    "    coin_data/\n",
    "    ├── two_euro/\n",
    "    │   ├── two_euro_0001.png\n",
    "    │   └── ...\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dset_path):\n",
    "        raise FileNotFoundError(f\"Directory '{dset_path}' does not exist.\")\n",
    "\n",
    "    coin_dirs = [d for d in os.listdir(dset_path) if os.path.isdir(os.path.join(dset_path, d))]\n",
    "    coin_dirs.sort()\n",
    "\n",
    "    if not coin_dirs:\n",
    "        raise ValueError(f\"No subdirectories found in the directory '{dset_path}'.\")\n",
    "\n",
    "    # Create label mapping\n",
    "    labels = {j: coin_name for j, coin_name in enumerate(coin_dirs)}\n",
    "    print(f\"Found {len(coin_dirs)} coin types:\")\n",
    "    for label, name in labels.items():\n",
    "        print(f\"  Label {label}: {name}\")\n",
    "\n",
    "    # Load all images\n",
    "    coin_images = {}  # label -> list of images\n",
    "    for label, coin_name in labels.items():\n",
    "        coin_path = os.path.join(dset_path, coin_name)\n",
    "\n",
    "        all_files = os.listdir(coin_path)\n",
    "        image_files = [f for f in all_files if f.lower().endswith('.png')]\n",
    "        image_files.sort()\n",
    "\n",
    "        images = []\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(coin_path, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "        coin_images[label] = images\n",
    "\n",
    "    # Balance datasets\n",
    "    all_images, all_labels = [], []\n",
    "    if balance_datasets:\n",
    "        smallest_dset = min(min(len(images) for images in coin_images.values()), max_size)\n",
    "        for label, images in coin_images.items():\n",
    "            all_images.extend(images[:smallest_dset])\n",
    "            all_labels.extend([label] * smallest_dset)\n",
    "    else:\n",
    "        for label, images in coin_images.items():\n",
    "            all_images.extend(images)\n",
    "            all_labels.extend([label] * len(images))\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.stack(all_images, axis=0)  # Shape: (N, H, W, C)\n",
    "    Y = np.array(all_labels)  # Shape: (N,)\n",
    "\n",
    "    return X, Y, labels"
   ],
   "id": "2776412dbedd7d5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 8: Train the Model\n",
    "\n",
    "Now we bring everything together:\n",
    "\n",
    "* Load the datasets and convert them to PyTorch tensors.\n",
    "* Create a DataLoader for batching and shuffling.\n",
    "* Initialize and train the CNN.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# TODO: Load datasets with `load_coin_datasets(\"coin_data_extracted\")`\n",
    "X, y, label_mapping = ...\n",
    "\n",
    "# TODO: Convert the images and labels to PyTorch tensors\n",
    "X_tensor = ...\n",
    "y_tensor = ...\n",
    "\n",
    "# TODO: Wrap the tensors in a TensorDataset and create a DataLoader\n",
    "dataset = ...\n",
    "dataloader = ...\n",
    "\n",
    "# Device selection\n",
    "if hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "    print(\"Using XPU (Intel Arc / oneAPI)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA (NVIDIA)\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon / macOS GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# TODO: Create the model (choose CoinClassifier or CoinClassifierEfficientNet) and move it to the device\n",
    "num_classes = len(label_mapping)\n",
    "model = ...\n",
    "\n",
    "# TODO: Define the loss function and optimizer\n",
    "criterion = ...\n",
    "optimizer = ...\n",
    "\n",
    "# TODO: Implement the training loop\n",
    "num_epochs = ...\n",
    "for epoch in range(num_epochs):\n",
    "    ...\n"
   ],
   "id": "51287df0ae3ae3b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 9: Predict from a Single Image\n",
    "\n",
    "We now define a helper function to classify one image with the trained PyTorch model.\n",
    "\n",
    "* The image is expanded with a batch dimension before inference.\n",
    "* The model returns class scores (logits).\n",
    "* The highest-scoring class is mapped back to its label.\n",
    "\"\"\"\n",
    "\n",
    "def predict_coin(image: np.ndarray, model: torch.nn.Module, label_mapping: dict[int, str]) -> str:\n",
    "    \"\"\"Predict coin type from a single image.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Ensure input is on the same device as the model\n",
    "    device = next(model.parameters()).device\n",
    "    input_batch = torch.from_numpy(np.expand_dims(image, axis=0)).to(torch.uint8).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_batch = model.preprocess(input_batch)\n",
    "        output = model(input_batch)\n",
    "\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    predicted_label = label_mapping[predicted_class]\n",
    "\n",
    "    return predicted_label\n"
   ],
   "id": "8b849ea52d8a6cec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 10: Test the Model\n",
    "\n",
    "Finally, let's check the trained model on a few random images.\n",
    "\n",
    "* Pick random samples from the dataset.\n",
    "* Run predictions with `predict_coin`.\n",
    "* Compare predicted vs. true labels.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(20):\n",
    "    idx = random.randint(0, len(X) - 1)\n",
    "    test_image = X[idx]\n",
    "    true_label = label_mapping[y[idx]]\n",
    "\n",
    "    predicted_label = predict_coin(test_image, model, label_mapping)\n",
    "    print(f\"True label: {true_label} | Predicted label: {predicted_label} | {true_label == predicted_label}\")\n"
   ],
   "id": "45b3b47024f1b3a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 11: Evaluate Accuracy\n",
    "\n",
    "Instead of just printing individual results,\n",
    "we can calculate overall accuracy across 100 random images.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "num_tests = 100\n",
    "correct = 0\n",
    "\n",
    "for i in range(num_tests):\n",
    "    idx = random.randint(0, len(X) - 1)\n",
    "    test_image = X[idx]\n",
    "    true_label = label_mapping[y[idx]]\n",
    "    predicted_label = predict_coin(test_image, model, label_mapping)\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / num_tests\n",
    "print(f\"Accuracy over {num_tests} random samples: {accuracy:.2%}\")\n"
   ],
   "id": "310acaa76c0affd9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
